{
  "name": "llama_cpp_evaluation",
  "version": "1.0.0",
  "type": "module",
  "bin": {
    "llama_cpp_evaluation": "bin/llama_cpp_evaluation.js"
  },
  "scripts": {
    "preinstall": "git submodule update --init --recursive",
    "evaluation": "node ./bin/llama_cpp_evaluation.js",
    "generate": "node ./bin/llama_cpp_evaluation.js generate myEval",
    "predict": "node ./bin/llama_cpp_evaluation.js predict myEval myPredict",
    "evaluate": "node ./bin/llama_cpp_evaluation.js evaluate myEval myPredict",
    "report": "node ./bin/llama_cpp_evaluation.js report myEval",
    "hptuning": "node ./bin/llama_cpp_evaluation.js hptuning myEval ./data/evaluations/hptunings/superHpTuning.hptuning.json5",
    "test": "cd test && npm test"
  },
  "keywords": ["llamacpp", "evaluation", "machine learning", "ml", "ai"],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "cli-color": "^2.0.3",
    "commander": "^11.1.0",
    "debug": "^4.3.4",
    "fs-extra": "^11.1.1",
    "json5": "^2.2.3",
    "langchain": "^0.0.172",
    "node-llama-cpp": "^2.7.3",
    "zod": "^3.22.4",
    "zod-to-json-schema": "^3.21.4"
  }
}
